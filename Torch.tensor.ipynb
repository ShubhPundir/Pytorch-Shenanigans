{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8935b08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cpu'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b965cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(1)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2bb967d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0924208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vec = torch.tensor([1,2])\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55524200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669ebd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a36fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix \n",
    "\n",
    "MATRIX = torch.tensor([[1,2],\n",
    "                       [2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a3303e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b33f45ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "783ae2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 3,  4,  5],\n",
       "         [ 5, 12,  4]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensor\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [3,4,5],\n",
    "                        [5,12,4]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c980b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72085424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5a41587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 3,  4,  5],\n",
       "        [ 5, 12,  4]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "305445c2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\robot\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\robot\\anaconda3\\lib\\site-packages (0.15.2)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp311-cp311-win_amd64.whl (3.9 MB)\n",
      "     ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.6/3.9 MB 13.4 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 1.2/3.9 MB 12.7 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.7/3.9 MB 12.3 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 2.3/3.9 MB 12.0 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 2.8/3.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 3.3/3.9 MB 11.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.9/3.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.9/3.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.9/3.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.9/3.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.9/3.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.9/3.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.9/3.9 MB 6.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\robot\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\robot\\anaconda3\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\robot\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\robot\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\robot\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\robot\\anaconda3\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 0.5/2.5 MB 14.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 1.0/2.5 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 1.6/2.5 MB 12.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 2.1/2.5 MB 12.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 MB 12.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\robot\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.0.2+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec098143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba7d2b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4867, 0.8912, 0.5263, 0.7068],\n",
       "        [0.4328, 0.6448, 0.9781, 0.4908],\n",
       "        [0.5918, 0.3256, 0.9921, 0.5435]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Tensors\n",
    "\n",
    "rand = torch.rand(3,4)\n",
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f64223f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.4662e-01, 9.2516e-01, 2.7449e-01],\n",
       "         [1.6001e-01, 5.4482e-01, 3.0038e-01],\n",
       "         [1.3288e-01, 8.1928e-01, 3.3540e-01],\n",
       "         ...,\n",
       "         [1.4517e-01, 5.6379e-01, 7.9808e-01],\n",
       "         [4.3415e-01, 4.2767e-01, 4.6685e-01],\n",
       "         [5.0673e-02, 9.1625e-01, 9.5731e-01]],\n",
       "\n",
       "        [[6.2637e-02, 3.4098e-01, 6.9699e-02],\n",
       "         [1.5517e-01, 3.4872e-01, 2.6324e-01],\n",
       "         [5.0088e-01, 2.2099e-01, 8.2395e-01],\n",
       "         ...,\n",
       "         [1.6801e-01, 4.6348e-01, 1.7265e-01],\n",
       "         [6.4591e-01, 8.4764e-04, 2.6885e-01],\n",
       "         [1.6810e-01, 4.6325e-01, 8.0876e-01]],\n",
       "\n",
       "        [[1.4404e-01, 4.8215e-01, 2.6361e-02],\n",
       "         [5.0089e-01, 7.1365e-01, 5.6500e-01],\n",
       "         [7.2154e-01, 1.4287e-02, 3.9427e-02],\n",
       "         ...,\n",
       "         [1.7693e-01, 1.1669e-01, 1.5447e-01],\n",
       "         [9.5941e-01, 7.9509e-01, 3.7176e-01],\n",
       "         [8.0689e-01, 5.4832e-01, 1.7649e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.0974e-01, 5.3565e-01, 5.2879e-01],\n",
       "         [9.5291e-01, 4.3501e-01, 8.2691e-01],\n",
       "         [4.5108e-02, 4.7515e-01, 5.6342e-01],\n",
       "         ...,\n",
       "         [3.5290e-01, 7.5835e-01, 2.5349e-01],\n",
       "         [2.9926e-01, 5.2389e-01, 4.6031e-01],\n",
       "         [5.2156e-01, 9.1104e-01, 7.6939e-01]],\n",
       "\n",
       "        [[9.6336e-01, 4.0491e-01, 5.6008e-01],\n",
       "         [9.1560e-01, 4.3030e-01, 1.7620e-01],\n",
       "         [3.8709e-01, 6.7451e-01, 1.2343e-01],\n",
       "         ...,\n",
       "         [6.4586e-01, 8.6351e-01, 9.0820e-01],\n",
       "         [7.3418e-01, 7.9266e-01, 6.8565e-01],\n",
       "         [9.4086e-01, 7.7729e-01, 6.7594e-01]],\n",
       "\n",
       "        [[1.7725e-02, 6.0087e-01, 4.0933e-01],\n",
       "         [7.9859e-01, 8.6911e-01, 3.7360e-02],\n",
       "         [6.9640e-01, 6.2236e-01, 3.0393e-01],\n",
       "         ...,\n",
       "         [4.8564e-01, 6.1735e-01, 9.9133e-01],\n",
       "         [1.7057e-01, 6.3150e-01, 4.3716e-01],\n",
       "         [5.9695e-01, 4.2208e-01, 9.1514e-02]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random image tensor\n",
    "\n",
    "random_image_tensor = torch.rand(size=(224,224,3))\n",
    "random_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e1ea578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e7880758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "386e1a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros((3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1dbfee3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand*zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8012010a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  2.5000,  4.0000,  5.5000,  7.0000,  8.5000, 10.0000, 11.5000],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1,12,1.5,dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1ef0ad26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4,5],\n",
    "             dtype=None,\n",
    "             device='cpu', \n",
    "             requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5ff1c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected one of cpu,\n",
    "# cuda, ipu, xpu, mkldnn,\n",
    "# opengl, opencl, ideep, hip, ve\n",
    "# , fpga, ort, xla, lazy, vulkan,\n",
    "# mps, meta, hpu, mtia, privateuseone\n",
    "# device type at start of device string: d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14d89c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.000252, 0.00195)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = 252 * pow(10,-6), 1.95 * pow(10,-3)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46ae5f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.738095238095238"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856ae20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1cb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874eba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a11843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce05996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b443a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a7dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe647e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd3b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53581da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89872e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a10f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95e902b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d41745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb9e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0e21e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ad51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0889fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dcd27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
